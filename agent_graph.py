import os
import json
from typing import TypedDict, List, Optional
from langgraph.graph import StateGraph, END
from langchain_google_vertexai import ChatVertexAI
from tools import check_eligibility, calculate_strength_score, validate_guardrails

# --- AUTHENTICATION ---
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "key.json"
MODEL_NAME = "gemini-2.5-flash"

class AgentState(TypedDict):
    history: List[str]
    user_profile: dict
    schemes_found: List[dict]
    next_step: str
    conflict_msg: Optional[str]

# --- NODE 1: COGNITION (THE FIX) ---
def cognition_node(state: AgentState):
    llm = ChatVertexAI(model=MODEL_NAME)
    current_profile = state.get('user_profile', {})
    last_message = state.get('history', [])[-1] if state.get('history') else ""
    
    # Check if we just asked a conflict question
    # If the previous step was 'resolve_conflict', the user is likely answering it.
    is_answering_conflict = state.get('next_step') == 'resolve_conflict'

    prompt = f"""
    You are VANI. Update the User Profile.
    
    Current Profile: {json.dumps(current_profile, ensure_ascii=False)}
    New Message: "{last_message}"
    Context: User is answering a conflict question? {is_answering_conflict}
    
    RULES:
    1. EXTRACT: name, age(int), gender, state, occupation, qualification, income(int), caste.
    2. TRANSLATE TO ENGLISH: Convert 'চাষী'->'Farmer', 'বেকার'->'Unemployed', 'পশ্চিমবঙ্গ'->'West Bengal'.
       - CRITICAL: Keep all other values (like name, gender, state) in BENGALI script exactly as the user spoke them. Only occupation and age(int) should be in English/Number.
    
    3. CONFLICT HANDLING (THE CRITICAL RULE):
       - IF "Context" is True (User is answering a clarification): TRUST THE NEW INPUT. Overwrite the old value. Do NOT flag conflict.
       - IF "Context" is False AND the user changes a value (e.g. Old Age 15, New Age 17): Flag "conflict": true.
       - IF the user says "Actually" or "No" (correction words): TRUST THE NEW INPUT. Overwrite.
    
    OUTPUT JSON ONLY:
    {{
        "conflict": boolean, 
        "question": "string (Bengali, only if conflict is true)", 
        "updated_profile": {{...}} 
    }}
    """
    try:
        response = llm.invoke(prompt)
        clean_text = response.content.replace("```json", "").replace("```", "").strip()
        data = json.loads(clean_text)
        
        # 1. Handle Conflict
        if data.get("conflict"):
            return {
                "next_step": "resolve_conflict",
                "conflict_msg": data.get("question")
            }

        # 2. Update Profile
        new_prof = data.get("updated_profile", state.get('user_profile', {}))
        
        # 3. Check Completeness
        # We check for these fields. If missing, we ask.
        # CHANGED HERE: Added 'income' and 'caste' to the mandatory list.
        mandatory = ['name', 'age', 'gender', 'state', 'occupation', 'income', 'caste']
        missing = [f for f in mandatory if not new_prof.get(f)]
        
        step = "ask_user" if missing else "run_tools"
        
        return {"user_profile": new_prof, "next_step": step, "conflict_msg": None}
    except Exception as e:
        print(f"Cognition Error: {e}")
        return {"next_step": "ask_user"}

# --- NODE 2: TOOLS (Standard) ---
def tool_node(state: AgentState):
    profile = state['user_profile']
    raw_schemes = check_eligibility(profile)
    final_results = []
    
    for s in raw_schemes:
        status, reason = validate_guardrails(profile, s)
        if status == "PASS":
            s['strength_score'] = calculate_strength_score(profile, s)
            final_results.append(s)
            
    final_results = sorted(final_results, key=lambda x: x.get('strength_score', 0), reverse=True)[:3]
    return {"schemes_found": final_results}

# --- NODE 3: GENERATOR (Standard) ---
def generator_node(state: AgentState):
    llm = ChatVertexAI(model=MODEL_NAME)
    profile = state['user_profile']
    schemes = state.get('schemes_found', [])
    step = state.get('next_step')
    
    system_rules = "You are VANI. Speak ONLY in Bengali. Do NOT use asterisks (*). Do NOT use markdown bolding."
    
    if step == "resolve_conflict":
        # Ask the clarification question generated by Cognition
        prompt = f"{system_rules} The user gave contradictory info. Ask this question: {state['conflict_msg']}"
        
    elif step == "ask_user":
        # Ask for missing fields
        # CHANGED HERE: Updated the list to include 'income' and 'caste' so the generator knows to ask for them.
        missing = [k for k in ['name', 'age', 'gender', 'state', 'occupation', 'income', 'caste'] if k not in profile]
        prompt = f"{system_rules} Current Profile: {profile}. Ask for missing fields: {missing} in Bengali."
        
    elif not schemes:
        prompt = f"{system_rules} Tell the user no schemes were found matching their profile."
        
    else:
        # EXPLAIN REASONING
        prompt = f"""{system_rules} 
        Greet {profile.get('name')}. List these schemes: {schemes}.
        CRITICAL: Explain WHY the user is eligible for each scheme based on their specific profile data.
        """
        
    response = llm.invoke(prompt)
    clean_text = response.content.replace("**", "").replace("*", "").replace("#", "").strip()
    return {"history": [clean_text]}

# --- GRAPH ---
workflow = StateGraph(AgentState)
workflow.add_node("cognition", cognition_node)
workflow.add_node("tools", tool_node)
workflow.add_node("generator", generator_node)

workflow.set_entry_point("cognition")

# LOGIC: Ensure 'resolve_conflict' routes back to 'generator' so it asks the question
def route(x):
    if x['next_step'] == 'run_tools': return 'tools'
    return 'generator' 

workflow.add_conditional_edges("cognition", route, {"tools": "tools", "generator": "generator"})
workflow.add_edge("tools", "generator")
workflow.add_edge("generator", END)

app_graph = workflow.compile()